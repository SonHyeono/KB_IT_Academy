{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqD4Sk9fmxFr"
   },
   "source": [
    "# STEP 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fyftyKdWo2d4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UodzHsxymfED"
   },
   "source": [
    "# STEP 1. Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1647998028002,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "zva6JRsxmMrg",
    "outputId": "26e1132f-4134-4c83-ba60-ebeb91b8b4b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sarcasm.json', <http.client.HTTPMessage at 0x20a5f7e5580>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n",
    "urllib.request.urlretrieve(url, 'sarcasm.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbFK72HxSDeX"
   },
   "source": [
    "`datas` 3개  출력\n",
    "* `article_link`: 뉴스 기사 URL\n",
    "* `headline`: 뉴스기사의 제목\n",
    "* `is_sarcastic`: 비꼬는 기사 여부 (비꼼: 1, 일반: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1647998031270,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "kFDm6br_mh-M",
    "outputId": "ee502a0e-9429-4b24-c20d-f0fc8a383fb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5',\n",
       "  'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
       "  'is_sarcastic': 0},\n",
       " {'article_link': 'https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365',\n",
       "  'headline': \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
       "  'is_sarcastic': 0},\n",
       " {'article_link': 'https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697',\n",
       "  'headline': \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
       "  'is_sarcastic': 1}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sarcasm.json') as f:\n",
    "    datas = json.load(f)\n",
    "datas[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEjfWJPqmuDU"
   },
   "source": [
    "# STEP 2. 전처리 (sentences, labels)\n",
    "* X (Feature): sentences\n",
    "* Y (Label): label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CAlFMNfqmpPU"
   },
   "outputs": [],
   "source": [
    "# 코드를 실행하세요.\n",
    "# 비어있는 리스트를 가지는 sentences와 labels 변수를 생성하세요.\n",
    "sentences = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yVDWHPi1SPTB"
   },
   "outputs": [],
   "source": [
    "# 반복문을 이용하여 datas의 데이터를 하나씩 data에 대입받으세요.\n",
    "  # 대입받은 data에서 키가 headline인 value를 sentences에 저장하세요.\n",
    "  # 대입받은 data에서 키가 is_sarcastic인 value를 labels에 저장하세요.\n",
    "\n",
    "for i in datas:\n",
    "    sentences.append(i['headline'])\n",
    "    labels.append(i['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1647998050789,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "agGPTtwLSbHv",
    "outputId": "93a2c8c4-52c8-4ae7-eb7f-a40779467009"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
       " \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
       " \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
       " 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas',\n",
       " 'j.k. rowling wishes snape happy birthday in the most magical way']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 슬라이싱을 이용하여 sentences에 저장된 5개를 조회하세요\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1647998053794,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "SF8tCWUoSeRx",
    "outputId": "2396b692-d0fb-4da8-ef31-15de41e963b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 슬라이싱을 이용하여 labels에 저장된 5개를 조회하세요\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "i5Yx9LVmSjdr"
   },
   "outputs": [],
   "source": [
    "# 슬라이싱을 이용하여 처음부터 20000까지를 train에 저장하세요\n",
    "training_size = 20000\n",
    "train_sentences = sentences[:training_size]\n",
    "train_labels = labels[:training_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DudpieKJSqFT"
   },
   "outputs": [],
   "source": [
    "# 슬라이싱을 이용하여 20000부터 마지막까지를 test에 저장하세요\n",
    "validation_sentences = sentences[training_size:]\n",
    "validation_labels = labels[training_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owGJH9aNSvr3"
   },
   "source": [
    "단어의 토큰화를 진행합니다.\n",
    "* `num_words`: 단어 max 사이즈를 지정합니다. 가장 **빈도수가 높은** 단어부터 저장합니다.\n",
    "* `oov_token`: 단어 토큰에 없는 단어를 어떻게 표기할 것인지 지정해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qNsyNG73St-7"
   },
   "outputs": [],
   "source": [
    "# 코드를 실행하세요.\n",
    "# vocab_size는 1000 oov_tok는 \"<OOV>\"라는 값을 가지도록 변수를 생성하세요.\n",
    "vocab_size = 1000\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FrWgkN4dS2-q"
   },
   "outputs": [],
   "source": [
    "# Tokenizer를 생성하세요. num_words는 vocab_size를 oov_token는 oov_tok를 지정하세요.\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iBbSFSFRS69H"
   },
   "outputs": [],
   "source": [
    "# 생성된 tokenizer의 fit_on_texts 함수를 이용하여 train_sentences를 피팅시키세요.\n",
    "tokenizer.fit_on_texts(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1647998520535,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "d16LHkAES_Z2",
    "outputId": "cc39395c-105f-4f30-aea1-a88b443dfc28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OOV>  \t======>\t 1\n",
      "to  \t======>\t 2\n",
      "of  \t======>\t 3\n",
      "the  \t======>\t 4\n",
      "in  \t======>\t 5\n",
      "for  \t======>\t 6\n",
      "a  \t======>\t 7\n",
      "on  \t======>\t 8\n",
      "and  \t======>\t 9\n",
      "with  \t======>\t 10\n",
      "is  \t======>\t 11\n",
      "new  \t======>\t 12\n",
      "trump  \t======>\t 13\n",
      "man  \t======>\t 14\n",
      "from  \t======>\t 15\n",
      "at  \t======>\t 16\n",
      "about  \t======>\t 17\n",
      "you  \t======>\t 18\n",
      "by  \t======>\t 19\n",
      "this  \t======>\t 20\n",
      "after  \t======>\t 21\n",
      "be  \t======>\t 22\n",
      "up  \t======>\t 23\n",
      "out  \t======>\t 24\n",
      "that  \t======>\t 25\n"
     ]
    }
   ],
   "source": [
    "# 코드를 실행하세요.\n",
    "# 사전 확인\n",
    "for key, value in tokenizer.word_index.items():\n",
    "    print(f'{key}  \\t======>\\t {value}')\n",
    "    if value == 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1647998112054,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "XGNB2-4MTG3v",
    "outputId": "e268b1d9-e87c-4152-a0ee-af256c62277d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25637"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰의 길이를 확인하세요.\n",
    "  # len 함수 이용\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OkPnSnNqTLX8"
   },
   "outputs": [],
   "source": [
    "# 피팅된 tokenizer의 texts_to_sequences 함수를 이용하여 데이터를 토큰화 시키세요.\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "validation_sequences = tokenizer.texts_to_sequences(validation_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647998113969,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "BKC4NHbdUEVy",
    "outputId": "3b539324-525a-43ec-a9a9-876add0f3379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[328, 1, 799, 1, 1, 47, 389, 1, 1, 6, 1, 1],\n",
       " [4, 1, 1, 1, 23, 2, 161, 1, 390, 1, 6, 251, 9, 889],\n",
       " [153, 890, 2, 891, 1, 1, 595, 1, 221, 133, 36, 45, 2, 1],\n",
       " [1, 38, 213, 382, 2, 1, 29, 288, 23, 10, 1, 1, 1, 958],\n",
       " [715, 672, 1, 1, 1, 662, 553, 5, 4, 92, 1, 90]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드를 실행하세요.\n",
    "# 토큰화 결과 확인\n",
    "train_sequences[:5]\n",
    "# 빈도수로 지정한 num_words=1000 에 의거하여, 빈도수가 1000번째보다 떨어지는 단어는 자동으로 1로 치환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1647999335725,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "u_05mjGIX94r",
    "outputId": "39b6c987-00e4-4852-e2d9-7a308635c2b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 38)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_sequences에서 각 문장의 단어 개수의 최대값과, validation_sequences에서 각 문장의 단어 개수의 최대값을 구하세요.\n",
    "max(len(i) for i in train_sequences), max(len(i) for i in validation_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ySQfy7JSUOLa"
   },
   "outputs": [],
   "source": [
    "## 그대로 실행하세요.\n",
    "# 한 문장의 최대 단어 숫자를 의미하는 max_length 변수를 만들고 40을 저장하세요.\n",
    "max_length = 40\n",
    "\n",
    "# 잘라낼 문장의 위치를 의미하는 trunc_type 변수를 만들고 'post'를 저장하세요.\n",
    "trunc_type='post'\n",
    "\n",
    "# 채워줄 문장의 위치를 의미하는 padding_type 변수를 만들고 'post'를 저장하세요.\n",
    "padding_type='post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ynXVUWcRUmhp"
   },
   "outputs": [],
   "source": [
    "# pad_sequences 함수를 이용하여 train_sequences과 validation_sequences에 패딩을 적용하세요.\n",
    " # maxlen는 max_length를, truncating는 trunc_type을, padding은 padding_type을 적용하세요.\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, truncating=trunc_type, padding=padding_type)\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, truncating=trunc_type, padding=padding_type) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1647998927051,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "tSCj6Md3UzIl",
    "outputId": "5e94142b-15aa-4509-bbec-2c700b485fa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 40), (6709, 40))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 패딩이 완료된 데이터의 shape을 조회하세요.\n",
    "train_padded.shape, validation_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1647999412514,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "tf6QxBNnaped",
    "outputId": "94c66de9-4d41-4405-d62d-0d83a87bea8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[328,   1, 799,   1,   1,  47, 389,   1,   1,   6,   1,   1,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [  4,   1,   1,   1,  23,   2, 161,   1, 390,   1,   6, 251,   9,\n",
       "        889,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [153, 890,   2, 891,   1,   1, 595,   1, 221, 133,  36,  45,   2,\n",
       "          1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_padded의 상위 3개의 데이터를 조회하세요.\n",
    "train_padded[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "7LRwoQKoU2up"
   },
   "outputs": [],
   "source": [
    "# train_labels과 validation_labels을 numpy array로 변경하세요.\n",
    "train_labels = np.array(train_labels)\n",
    "validation_labels = np.array(validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSRWqyPyVI0W"
   },
   "source": [
    "# STEP 3. 모델 정의 (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 663,
     "status": "ok",
     "timestamp": 1648000508923,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "etFKfB7jdndj",
    "outputId": "787c66fe-4705-4351-c568-7277c9cbb7a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 40, 16)            16000     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,849\n",
      "Trainable params: 38,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## 모델을 정의하세요. (Embedding Layer ==> RNN(LSTM, GRU) Layer ==>  Dense Layer)\n",
    "# Embedding Layer의 output size는 16으로 지정하세요.\n",
    "# Embedding Layer의 input_length는 max_length로 지정하세요.\n",
    "model = Sequential()\n",
    "embd = Embedding(vocab_size ,16, input_length=max_length)\n",
    "model.add(embd)\n",
    "model.add(LSTM(units=64))\n",
    "model.add(Dense(32, activation='sigmoid'))  # relu 보다 sigmoid가 성능이 더 좋았음.\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flo24D5ufpKp"
   },
   "source": [
    "# STEP 4. 컴파일 (compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "5Un9S86ofpKq"
   },
   "outputs": [],
   "source": [
    "# adam과 binary_crossentropy를 사용하여 모델을 컴파일하세요.\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9G7zJtNfpKq"
   },
   "source": [
    "## ModelCheckpoint: 체크포인트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "1SqS9L3MfpKr"
   },
   "outputs": [],
   "source": [
    "# 코드를 실행하세요.\n",
    "# ModelCheckpoint를 생성하세요.\n",
    "checkpoint = ModelCheckpoint('model.h5',\n",
    "                             save_best_only=True, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83470,
     "status": "ok",
     "timestamp": 1648000592692,
     "user": {
      "displayName": "­박건우",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkzHxU40PT8D263sWDJkdWREc2VjfSWthm9fa_=s64",
      "userId": "05168116895659168000"
     },
     "user_tz": -540
    },
    "id": "M9110ZM7fpKr",
    "outputId": "bf0e08d5-07b8-4835-8814-cbb86ad44de8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7025 - acc: 0.5479\n",
      "Epoch 1: val_loss improved from inf to 0.68699, saving model to model.h5\n",
      "250/250 [==============================] - 6s 19ms/step - loss: 0.7025 - acc: 0.5479 - val_loss: 0.6870 - val_acc: 0.5727\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6618 - acc: 0.6012\n",
      "Epoch 2: val_loss improved from 0.68699 to 0.49419, saving model to model.h5\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.6618 - acc: 0.6012 - val_loss: 0.4942 - val_acc: 0.7790\n",
      "Epoch 3/15\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.4329 - acc: 0.8088\n",
      "Epoch 3: val_loss improved from 0.49419 to 0.40241, saving model to model.h5\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.4326 - acc: 0.8086 - val_loss: 0.4024 - val_acc: 0.8198\n",
      "Epoch 4/15\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.3809 - acc: 0.8334\n",
      "Epoch 4: val_loss did not improve from 0.40241\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3809 - acc: 0.8337 - val_loss: 0.4566 - val_acc: 0.8045\n",
      "Epoch 5/15\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.3656 - acc: 0.8399\n",
      "Epoch 5: val_loss improved from 0.40241 to 0.40052, saving model to model.h5\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3658 - acc: 0.8400 - val_loss: 0.4005 - val_acc: 0.8253\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3590 - acc: 0.8433\n",
      "Epoch 6: val_loss did not improve from 0.40052\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3590 - acc: 0.8433 - val_loss: 0.4095 - val_acc: 0.8270\n",
      "Epoch 7/15\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.3562 - acc: 0.8424\n",
      "Epoch 7: val_loss improved from 0.40052 to 0.39241, saving model to model.h5\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3568 - acc: 0.8422 - val_loss: 0.3924 - val_acc: 0.8232\n",
      "Epoch 8/15\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3508 - acc: 0.8466\n",
      "Epoch 8: val_loss did not improve from 0.39241\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3510 - acc: 0.8464 - val_loss: 0.4114 - val_acc: 0.8165\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3469 - acc: 0.8468\n",
      "Epoch 9: val_loss did not improve from 0.39241\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3469 - acc: 0.8468 - val_loss: 0.3992 - val_acc: 0.8265\n",
      "Epoch 10/15\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3410 - acc: 0.8468\n",
      "Epoch 10: val_loss did not improve from 0.39241\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3410 - acc: 0.8467 - val_loss: 0.4073 - val_acc: 0.8213\n",
      "Epoch 11/15\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.3337 - acc: 0.8460\n",
      "Epoch 11: val_loss did not improve from 0.39241\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3330 - acc: 0.8465 - val_loss: 0.4093 - val_acc: 0.8217\n",
      "Epoch 12/15\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.3284 - acc: 0.8465\n",
      "Epoch 12: val_loss did not improve from 0.39241\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3281 - acc: 0.8468 - val_loss: 0.3997 - val_acc: 0.8242\n",
      "Epoch 13/15\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.3224 - acc: 0.8469\n",
      "Epoch 13: val_loss did not improve from 0.39241\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3224 - acc: 0.8468 - val_loss: 0.4138 - val_acc: 0.8087\n",
      "Epoch 14/15\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.3196 - acc: 0.8472\n",
      "Epoch 14: val_loss did not improve from 0.39241\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3191 - acc: 0.8472 - val_loss: 0.4375 - val_acc: 0.8188\n",
      "Epoch 15/15\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3185 - acc: 0.8444\n",
      "Epoch 15: val_loss did not improve from 0.39241\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3185 - acc: 0.8444 - val_loss: 0.4470 - val_acc: 0.8210\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 학습하세요,\n",
    "hist = model.fit(train_padded, train_labels, epochs=15, verbose=1, callbacks=[checkpoint],batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "AmCSlK8-fpKr"
   },
   "outputs": [],
   "source": [
    "# load_model 함수로 저장된 모델을 불러오세요\n",
    "loaded_model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 2s 6ms/step - loss: 0.4002 - acc: 0.8198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4001697301864624, 0.8197942972183228]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate 함수를 이용하여 모델의 성능을 평가하세요\n",
    "loaded_model.evaluate(validation_padded, validation_labels, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KB_HW6_뉴스풍자_분류_Q.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
